{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/verammaz/KMeans-VAE/blob/main/run_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# VAE Training Pipeline on Google Colab\n",
        "\n",
        "This notebook provides a complete workflow for:\n",
        "1. Setting up the environment\n",
        "2. Generating synthetic datasets (Gaussian & Bernoulli)\n",
        "3. Training a Variational Autoencoder (VAE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Setup & Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvLrbXCciexp"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_packages"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "! pip install -q torch tqdm matplotlib wandb\n",
        "\n",
        "print(\"Packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# Check available device\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_code"
      },
      "source": [
        "## Clone GitHub Repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clone_repo"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/verammaz/KMeans-VAE.git\n",
        "%cd KMeans-VAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wandb_setup"
      },
      "source": [
        "## W&B Setup\n",
        "\n",
        "If you want to log experiments to Weights & Biases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "collapsed": true,
        "id": "wandb_login"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W&B configured!\n"
          ]
        }
      ],
      "source": [
        "USE_WANDB = True \n",
        "\n",
        "if USE_WANDB:\n",
        "    import wandb\n",
        "    wandb.login()\n",
        "    print(\"W&B configured!\")\n",
        "else:\n",
        "    print(\"W&B logging disabled. Set USE_WANDB=True to enable.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data_gen_section"
      },
      "source": [
        "## Step 1: Generate Synthetic Datasets\n",
        "\n",
        "Generate both Gaussian and Bernoulli mixture datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Specify parameters for data generation\n",
        "DATA_DIR = './datasets'\n",
        "k = 5\n",
        "dims = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "generate_data"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Per-dataset per-component counts: [102475, 102475, 102475, 102475, 102475] (dims=64)\n",
            "Wrote ./datasets/gaussian_raw  (~127.05 MB)\n",
            "Wrote ./datasets/bernoulli_raw   (~127.05 MB)\n",
            "Total on disk â‰ˆ 254.10 MB (target 256.00 MB)\n"
          ]
        }
      ],
      "source": [
        "# Generate datasets\n",
        "! python data/make_datasets.py \\\n",
        "    --k {k} \\\n",
        "    --dims {dims} \\\n",
        "    --target-mb 256 \\\n",
        "    --seed 42 \\\n",
        "    --outroot {DATA_DIR}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "check_data"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "gaussian_raw:\n",
            "  Type: gaussian\n",
            "  Classes: 5\n",
            "  Dimensions: 64\n",
            "  Samples per class: [102475, 102475, 102475, 102475, 102475]\n",
            "\n",
            "bernoulli_raw:\n",
            "  Type: bernoulli\n",
            "  Classes: 5\n",
            "  Dimensions: 64\n",
            "  Samples per class: [102475, 102475, 102475, 102475, 102475]\n"
          ]
        }
      ],
      "source": [
        "# Verify data generation\n",
        "import os\n",
        "import json\n",
        "\n",
        "for dataset in ['gaussian_raw', 'bernoulli_raw']:\n",
        "    path = f'{DATA_DIR}/{dataset}'\n",
        "    if os.path.exists(path):\n",
        "        with open(os.path.join(path, 'metadata.json')) as f:\n",
        "            meta = json.load(f)\n",
        "        print(f\"\\n{dataset}:\")\n",
        "        print(f\"  Type: {meta['type']}\")\n",
        "        print(f\"  Classes: {meta['k']}\")\n",
        "        print(f\"  Dimensions: {meta['dims']}\")\n",
        "        print(f\"  Samples per class: {meta['n_per']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_section"
      },
      "source": [
        "## Step 2: Train VAE\n",
        "\n",
        "Choose your configuration and train the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config_section"
      },
      "source": [
        "### Configuration Options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "config_params"
      },
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "CONFIG = {\n",
        "    # Dataset\n",
        "    'dataset': 'gaussian',  # 'gaussian' or 'bernoulli'\n",
        "\n",
        "    # Model \n",
        "    'model_name': None,   # Auto-generated if None\n",
        "    'latent_dim': 10,\n",
        "    'hidden_dims': [128, 64],\n",
        "    'kl_beta': 1.0,  # 1.0 = standard VAE, >1.0 = beta-VAE\n",
        "    'activation': 'LeakyReLU',\n",
        "\n",
        "    # Training\n",
        "    'epochs': 1,\n",
        "    'batch_size': 128,\n",
        "    'lr': 3e-4,\n",
        "    'optimizer': 'adam',\n",
        "\n",
        "    # System\n",
        "    'seed': 3407,\n",
        "    'device': 'auto',  # 'auto', 'cuda', 'cpu'\n",
        "\n",
        "    # W&B (if enabled)\n",
        "    'use_wandb': USE_WANDB,\n",
        "    'wandb_project': 'vae-colab-experiments',\n",
        "    'wandb_name': None,  # Auto-generated if None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_command"
      },
      "source": [
        "### Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "train_model"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training command:\n",
            "\n",
            "python -m vae.main     --data.data_dir=datasets/gaussian_raw     --model.name=None\n",
            "    --model.latent_dim=10     --model.hidden_dims='[128,64]'     --model.kl_beta=1.0     --model.activation=LeakyReLU     --trainer.epochs=1     --trainer.batch_size=128     --trainer.lr=0.0003     --trainer.optimizer=adam     --trainer.device=auto     --system.seed=3407      --wandb.enabled=True     --wandb.project=vae-colab-experiments\n",
            "\n",
            "============================================================\n",
            "Starting training...\n",
            "============================================================\n",
            "\n",
            "command line overwriting config attribute data.data_dir with datasets/gaussian_raw\n",
            "command line overwriting config attribute model.name with None\n",
            "Configuration:\n",
            "system:\n",
            "    seed: 3407\n",
            "    out_dir: ./out\n",
            "wandb:\n",
            "    enabled: False\n",
            "    project: kmeans-vae\n",
            "    entity: None\n",
            "    name: None\n",
            "    tags: []\n",
            "    notes: \n",
            "    log_freq: 10\n",
            "data:\n",
            "    data_dir: datasets/gaussian_raw\n",
            "model:\n",
            "    name: None\n",
            "    latent_dim: 10\n",
            "    hidden_dims: [128, 64]\n",
            "    likelihood: gaussian\n",
            "    kl_beta: 1.0\n",
            "    seed: 42\n",
            "    activation: LeakyReLU\n",
            "trainer:\n",
            "    device: auto\n",
            "    num_workers: 4\n",
            "    batch_size: 64\n",
            "    lr: 0.0003\n",
            "    epochs: 50\n",
            "    optimizer: adam\n",
            "    weight_decay: 0.0\n",
            "    beta1: 0.9\n",
            "    beta2: 0.999\n",
            "    eps: 1e-08\n",
            "    grad_norm_clip: 1.0\n",
            "\n",
            "\n",
            "Loading dataset from datasets/gaussian_raw\n",
            "Train set: 435520 samples, 64 features\n",
            "Test set:  76855 samples\n",
            "Classes:   5\n",
            "\n",
            "Creating VAE model:\n",
            "  Input dim:    64\n",
            "  Latent dim:   10\n",
            "  Hidden dims:  [128, 64]\n",
            "  Likelihood:   gaussian\n",
            "  Beta (KL):    1.0\n",
            "  Activation:   LeakyReLU\n",
            "\n",
            "Training on device: mps\n",
            "Starting training...\n",
            "============================================================\n",
            "Epoch 1/50 | Train Loss: 18.9566 (Recon: 13.8079, KL: 5.1487)                   \n",
            "Epoch 2/50 | Train Loss: 16.9489 (Recon: 12.7169, KL: 4.2321)                   \n",
            "Epoch 3/50 | Train Loss: 16.0722 (Recon: 12.4838, KL: 3.5884)                   \n",
            "Epoch 4/50 | Train Loss: 15.7755 (Recon: 12.3853, KL: 3.3902)                   \n",
            "Epoch 5/50 | Train Loss: 15.6826 (Recon: 12.3433, KL: 3.3394)                   \n",
            "Epoch 6/50 | Train Loss: 15.6221 (Recon: 12.3122, KL: 3.3099)                   \n",
            "Epoch 7/50 | Train Loss: 15.5795 (Recon: 12.2733, KL: 3.3061)                   \n",
            "Epoch 8/50 | Train Loss: 15.5447 (Recon: 12.2384, KL: 3.3062)                   \n",
            "Epoch 9/50 | Train Loss: 15.5209 (Recon: 12.2211, KL: 3.2998)                   \n",
            "Epoch 10/50 | Train Loss: 15.4955 (Recon: 12.2022, KL: 3.2932)                  \n",
            "Epoch 11/50 | Train Loss: 15.4863 (Recon: 12.1950, KL: 3.2913)                  \n",
            "Epoch 12/50 | Train Loss: 15.4749 (Recon: 12.1872, KL: 3.2877)                  \n",
            "Epoch 13/50 | Train Loss: 15.4536 (Recon: 12.1751, KL: 3.2785)                  \n",
            "Epoch 14/50 | Train Loss: 15.4446 (Recon: 12.1681, KL: 3.2765)                  \n",
            "Epoch 15/50 | Train Loss: 15.4297 (Recon: 12.1653, KL: 3.2644)                  \n",
            "Epoch 16/50 | Train Loss: 15.4191 (Recon: 12.1558, KL: 3.2633)                  \n",
            "Epoch 17/50 | Train Loss: 15.4046 (Recon: 12.1522, KL: 3.2524)                  \n",
            "Epoch 18/50 | Train Loss: 15.3955 (Recon: 12.1487, KL: 3.2467)                  \n",
            "Epoch 19/50 | Train Loss: 15.3867 (Recon: 12.1506, KL: 3.2360)                  \n",
            "Epoch 20/50 | Train Loss: 15.3858 (Recon: 12.1540, KL: 3.2318)                  \n",
            "Epoch 21/50 | Train Loss: 15.3686 (Recon: 12.1489, KL: 3.2197)                  \n",
            "Epoch 22/50 | Train Loss: 15.3694 (Recon: 12.1506, KL: 3.2188)                  \n",
            "Epoch 23/50 | Train Loss: 15.3486 (Recon: 12.1347, KL: 3.2139)                  \n",
            "Epoch 24/50 | Train Loss: 15.3448 (Recon: 12.1367, KL: 3.2081)                  \n",
            "Epoch 25/50 | Train Loss: 15.3330 (Recon: 12.1352, KL: 3.1977)                  \n",
            "Epoch 26/50 | Train Loss: 15.3318 (Recon: 12.1361, KL: 3.1957)                  \n",
            "Epoch 27/50 | Train Loss: 15.3265 (Recon: 12.1340, KL: 3.1924)                  \n",
            "Epoch 28/50 | Train Loss: 15.3187 (Recon: 12.1326, KL: 3.1860)                  \n",
            "Epoch 29/50 | Train Loss: 15.3150 (Recon: 12.1264, KL: 3.1885)                  \n",
            "Epoch 30/50 | Train Loss: 15.3086 (Recon: 12.1240, KL: 3.1846)                  \n",
            "Epoch 31/50 | Train Loss: 15.3020 (Recon: 12.1244, KL: 3.1776)                  \n",
            "Epoch 32/50 | Train Loss: 15.2935 (Recon: 12.1258, KL: 3.1677)                  \n",
            "Epoch 33/50 | Train Loss: 15.2899 (Recon: 12.1213, KL: 3.1685)                  \n",
            "Epoch 34/50 | Train Loss: 15.2866 (Recon: 12.1230, KL: 3.1636)                  \n",
            "Epoch 35/50 | Train Loss: 15.2869 (Recon: 12.1233, KL: 3.1637)                  \n",
            "Epoch 36/50 | Train Loss: 15.2696 (Recon: 12.1173, KL: 3.1523)                  \n",
            "Epoch 37/50 | Train Loss: 15.2753 (Recon: 12.1205, KL: 3.1548)                  \n",
            "Epoch 38/50 | Train Loss: 15.2688 (Recon: 12.1131, KL: 3.1557)                  \n",
            "Epoch 39/50 | Train Loss: 15.2755 (Recon: 12.1139, KL: 3.1616)                  \n",
            "Epoch 40/50 | Train Loss: 15.2649 (Recon: 12.1109, KL: 3.1540)                  \n",
            "Epoch 41/50 | Train Loss: 15.2684 (Recon: 12.1147, KL: 3.1537)                  \n",
            "Epoch 42/50 | Train Loss: 15.2631 (Recon: 12.1194, KL: 3.1438)                  \n",
            "Epoch 43/50 | Train Loss: 15.2607 (Recon: 12.1158, KL: 3.1449)                  \n",
            "Epoch 44/50 | Train Loss: 15.2585 (Recon: 12.1089, KL: 3.1497)                  \n",
            "Epoch 45/50 | Train Loss: 15.2565 (Recon: 12.1183, KL: 3.1383)                  \n",
            "Epoch 46/50 | Train Loss: 15.2543 (Recon: 12.1130, KL: 3.1413)                  \n",
            "Epoch 47/50 | Train Loss: 15.2549 (Recon: 12.1183, KL: 3.1366)                  \n",
            "Epoch 48/50 | Train Loss: 15.2567 (Recon: 12.1170, KL: 3.1397)                  \n",
            "Epoch 49/50 | Train Loss: 15.2469 (Recon: 12.1106, KL: 3.1363)                  \n",
            "Epoch 50/50 | Train Loss: 15.2426 (Recon: 12.1164, KL: 3.1261)                  \n",
            "\n",
            "Training completed!\n",
            "\n",
            "============================================================\n",
            "Test Set Evaluation\n",
            "============================================================\n",
            "Test Loss:        15.2673\n",
            "  Reconstruction: 12.1579\n",
            "  KL Divergence:  3.1094\n",
            "\n",
            "Saved final model to ./out/vae_gaus_i64_k5_z10_beta1.0/model.pt\n",
            "zsh:3: command not found: --model.latent_dim=10\n"
          ]
        }
      ],
      "source": [
        "# Build command line arguments\n",
        "data_dir = f\"{DATA_DIR.replace('./', '')}/{CONFIG['dataset']}_raw\"\n",
        "hidden_dims_str = f\"'{str(CONFIG['hidden_dims']).replace(' ', '')}'\"\n",
        "\n",
        "cmd = f\"\"\"\n",
        "python -m vae.main \\\n",
        "    --data.data_dir={data_dir} \\\n",
        "    --model.latent_dim={CONFIG['latent_dim']} \\\n",
        "    --model.hidden_dims={hidden_dims_str} \\\n",
        "    --model.kl_beta={CONFIG['kl_beta']} \\\n",
        "    --model.activation={CONFIG['activation']} \\\n",
        "    --trainer.epochs={CONFIG['epochs']} \\\n",
        "    --trainer.batch_size={CONFIG['batch_size']} \\\n",
        "    --trainer.lr={CONFIG['lr']} \\\n",
        "    --trainer.optimizer={CONFIG['optimizer']} \\\n",
        "    --trainer.device={CONFIG['device']} \\\n",
        "    --system.seed={CONFIG['seed']} \\\n",
        "\"\"\"\n",
        "\n",
        "# Add W&B flags if enabled\n",
        "if CONFIG['use_wandb']:\n",
        "    cmd += f\" \\\n",
        "    --wandb.enabled=True \\\n",
        "    --wandb.project={CONFIG['wandb_project']}\"\n",
        "    if CONFIG['wandb_name']:\n",
        "        cmd += f\" \\\n",
        "    --wandb.name={CONFIG['wandb_name']}\"\n",
        "\n",
        "print(\"Training command:\")\n",
        "print(cmd)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Starting training...\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "# Run training\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name:  vae_gaus_i64_k5_z10_beta1.0\n"
          ]
        }
      ],
      "source": [
        "if CONFIG['model_name'] is None:\n",
        "    dataset = 'gaus' if CONFIG['dataset'] == 'gaussian' else 'ber'\n",
        "    MODEL_NAME = f\"vae_{dataset}_i{dims}_k{k}_z{CONFIG['latent_dim']}_beta{CONFIG['kl_beta']}\"\n",
        "else:\n",
        "    MODEL_NAME = CONFIG['model_name']\n",
        "\n",
        "if USE_WANDB:\n",
        "    RUN_NAME = MODEL_NAME if CONFIG['wandb_name'] is None else CONFIG['wandb_name']\n",
        "\n",
        "\n",
        "print(\"Model name: \", MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "analysis_section"
      },
      "source": [
        "## Step 3: Analyze Results\n",
        "\n",
        "Load the trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_model"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from vae.model import VAE\n",
        "from data.data_io import load_and_split\n",
        "\n",
        "# Load trained model\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "checkpoint = torch.load(os.path.join('./out', f'{MODEL_NAME}/model.pt'), map_location=device)\n",
        "config = checkpoint['config']\n",
        "\n",
        "print(\"Model configuration:\")\n",
        "print(f\"  Latent dim: {config['model']['latent_dim']}\")\n",
        "print(f\"  Hidden dims: {config['model']['hidden_dims']}\")\n",
        "print(f\"  Beta: {config['model']['kl_beta']}\")\n",
        "print(f\"\\nTest statistics:\")\n",
        "for k, v in checkpoint['test_stats'].items():\n",
        "    print(f\"  {k}: {v:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "recreate_model"
      },
      "outputs": [],
      "source": [
        "# Recreate model\n",
        "model_config = config['model']\n",
        "input_dim = checkpoint['model_state_dict']['mean.weight'].shape[1]\n",
        "\n",
        "model = VAE(\n",
        "    input_dim=input_dim,\n",
        "    latent_dim=model_config['latent_dim'],\n",
        "    hidden_dims=model_config['hidden_dims'],\n",
        "    likelihood=model_config['likelihood'],\n",
        "    beta=model_config['kl_beta'],\n",
        "    activation=model_config.get('activation', 'LeakyReLU')\n",
        ")\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_test_data"
      },
      "outputs": [],
      "source": [
        "# Load test data\n",
        "data_dir = config['data']['data_dir']\n",
        "data = load_and_split(data_dir, normalize=True)\n",
        "\n",
        "X_test = torch.tensor(data['X_test'], dtype=torch.float32).to(device)\n",
        "y_test = torch.tensor(data['y_test'], dtype=torch.long)\n",
        "\n",
        "print(f\"Test set: {X_test.shape[0]} samples, {X_test.shape[1]} features\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## Download Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To Local Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# Zip the output directory\n",
        "!zip -r vae_results.zip out/\n",
        "\n",
        "print(\"Results zipped!\")\n",
        "print(\"Download 'vae_results.zip' from the file browser on the left.\")\n",
        "\n",
        "# Zip the data directory\n",
        "!zip -r data.zip {DATA_DIR}\n",
        "\n",
        "print(\"Data zipped!\")\n",
        "print(\"Download 'data.zip' from the file browser on the left.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### To Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r out/ /content/drive/MyDrive/vae/\n",
        "\n",
        "!cp -r {DATA_DIR} /content/drive/MyDrive/data/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### From W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "artifact/2148009639/wandb_manifest.json\n",
            "config.yaml\n",
            "data/data_set/gaussian_raw/centers.npy\n",
            "data/data_set/gaussian_raw/gauss_c0_X.npy\n",
            "data/data_set/gaussian_raw/gauss_c0_y.npy\n",
            "data/data_set/gaussian_raw/gauss_c1_X.npy\n",
            "data/data_set/gaussian_raw/gauss_c1_y.npy\n",
            "data/data_set/gaussian_raw/gauss_c2_X.npy\n",
            "data/data_set/gaussian_raw/gauss_c2_y.npy\n",
            "data/data_set/gaussian_raw/gauss_c3_X.npy\n",
            "data/data_set/gaussian_raw/gauss_c3_y.npy\n",
            "data/data_set/gaussian_raw/gauss_c4_X.npy\n",
            "data/data_set/gaussian_raw/gauss_c4_y.npy\n",
            "data/data_set/gaussian_raw/metadata.json\n",
            "data/data_set/gaussian_raw/splits.json\n",
            "data/data_set/gaussian_raw/variances.npy\n",
            "out/vae_gaus_i64_k5_z10_beta1.0/model.pt\n",
            "output.log\n",
            "requirements.txt\n",
            "wandb-metadata.json\n",
            "wandb-summary.json\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<_io.TextIOWrapper name='./out/vae_gaus_i64_k5_z10_beta1.0/model.pt' mode='r' encoding='UTF-8'>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "api = wandb.Api()\n",
        "\n",
        "# Replace these:\n",
        "entity = \"vmm2146-columbia-university\"      # your wandb username or team\n",
        "project = CONFIG['wandb_project']           # your wandb project name\n",
        "run_id = \"f10w6e5f\"                         # your run id\n",
        "\n",
        "run = api.run(f\"{entity}/{project}/runs/{run_id}\")\n",
        "\n",
        "# List files stored in this run\n",
        "for f in run.files():\n",
        "    print(f.name)\n",
        "\n",
        "# Download a specific file (e.g., model checkpoint)\n",
        "run.file(f\"out/{MODEL_NAME}/model.pt\").download(root=\".\", replace=True)\n",
        "\n",
        "# List and download all files matching that prefix\n",
        "for f in run.files():\n",
        "    if f.name.startswith(DATA_DIR):\n",
        "        print(f\"Downloading {f.name} ...\")\n",
        "        f.download(root=\".\", replace=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_section"
      },
      "source": [
        "## Experiment: Compare Different Beta Values\n",
        "\n",
        "Run a quick sweep to see the effect of different beta values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtULqONGli_Q"
      },
      "outputs": [],
      "source": [
        "# Sweep different beta values\n",
        "beta_values = [0.5, 1.0, 2.0, 4.0]\n",
        "\n",
        "for beta in beta_values:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Training with beta = {beta}\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    cmd = f\"\"\"python main.py \\\\\n",
        "        --data.data_dir=./data_set/gaussian_raw \\\\\n",
        "        --model.kl_beta={beta} \\\\\n",
        "        --model.latent_dim=10 \\\\\n",
        "        --trainer.epochs=30 \\\\\n",
        "        --trainer.batch_size=128 \\\\\n",
        "        --system.out_dir=./out/vae_beta_{beta}\"\"\"\n",
        "\n",
        "    if USE_WANDB:\n",
        "        cmd += f\" \\\\\\n        --wandb.enabled=True \\\\\\n        --wandb.name=beta_{beta}\"\n",
        "\n",
        "    # Execute command\n",
        "    import os\n",
        "    os.system(cmd.replace('\\\\\\n', ' '))\n",
        "\n",
        "print(\"\\nBeta sweep complete! Check out/vae_beta_* directories for results.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
